{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMixer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stage1_train_path: str,\n",
    "        stage1_valid_path: str,\n",
    "        stage2_train_path: str,\n",
    "        stage2_valid_path: str,\n",
    "        mix_ratio: dict = {\"stage1\": 0.7, \"stage2\": 0.3},\n",
    "        target_train_size: int = 80000,  # 期望的训练集总数\n",
    "        target_valid_size: int = 1000,    # 期望的验证集总数\n",
    "        output_dir: str = \"stage2/data_mixed\"\n",
    "    ):\n",
    "        \"\"\"初始化数据集混合器\n",
    "        \n",
    "        Args:\n",
    "            stage1_train_path: 第一阶段训练数据路径\n",
    "            stage1_valid_path: 第一阶段验证数据路径\n",
    "            stage2_train_path: 第二阶段训练数据路径\n",
    "            stage2_valid_path: 第二阶段验证数据路径\n",
    "            mix_ratio: 混合比例，字典格式，键为stage名称，值为比例\n",
    "            target_train_size: 期望的训练集总数\n",
    "            target_valid_size: 期望的验证集总数\n",
    "            output_dir: 输出目录\n",
    "        \"\"\"\n",
    "        self.stage1_train_path = stage1_train_path\n",
    "        self.stage1_valid_path = stage1_valid_path\n",
    "        self.stage2_train_path = stage2_train_path\n",
    "        self.stage2_valid_path = stage2_valid_path\n",
    "        self.mix_ratio = mix_ratio\n",
    "        self.target_train_size = target_train_size\n",
    "        self.target_valid_size = target_valid_size\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # 验证比例和是否为1\n",
    "        if abs(sum(mix_ratio.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"混合比例之和必须为1\")\n",
    "            \n",
    "        # 确保输出目录存在\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"加载所有数据集\"\"\"\n",
    "        print(\"正在加载数据集...\")\n",
    "        \n",
    "        # 加载stage1数据\n",
    "        with open(self.stage1_train_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage1_train = json.load(f)\n",
    "        with open(self.stage1_valid_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage1_valid = json.load(f)\n",
    "            \n",
    "        # 加载stage2数据\n",
    "        with open(self.stage2_train_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage2_train = json.load(f)\n",
    "        with open(self.stage2_valid_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage2_valid = json.load(f)\n",
    "            \n",
    "        print(f\"✓ Stage1 训练集: {len(self.stage1_train)} 条数据\")\n",
    "        print(f\"✓ Stage1 验证集: {len(self.stage1_valid)} 条数据\")\n",
    "        print(f\"✓ Stage2 训练集: {len(self.stage2_train)} 条数据\")\n",
    "        print(f\"✓ Stage2 验证集: {len(self.stage2_valid)} 条数据\")\n",
    "\n",
    "    def analyze_types(self, data):\n",
    "        \"\"\"分析数据集中各个类型的分布\n",
    "        \n",
    "        Args:\n",
    "            data: 要分析的数据集\n",
    "        \"\"\"\n",
    "        type_counts = {}\n",
    "        for item in data:\n",
    "            type_name = item.get('type', 'unknown')\n",
    "            type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
    "            \n",
    "        print(\"\\n数据类型分布:\")\n",
    "        for type_name, count in type_counts.items():\n",
    "            percentage = (count / len(data)) * 100\n",
    "            print(f\"- {type_name}: {count} 条 ({percentage:.2f}%)\")\n",
    "            \n",
    "        return type_counts\n",
    "    \n",
    "    def mix_data(self, data1, data2, ratio1, target_size):\n",
    "        \"\"\"混合两个数据集\n",
    "        \n",
    "        Args:\n",
    "            data1: 第一个数据集\n",
    "            data2: 第二个数据集\n",
    "            ratio1: 第一个数据集的目标比例\n",
    "            target_size: 期望的混合后数据集大小\n",
    "        \"\"\"\n",
    "        # 计算每个数据集需要的样本数\n",
    "        target_size1 = int(target_size * ratio1)\n",
    "        target_size2 = target_size - target_size1\n",
    "        \n",
    "        # 确保采样数量不超过可用数据量\n",
    "        if target_size1 > len(data1) or target_size2 > len(data2):\n",
    "            print(\"警告：目标数量超过可用数据量，将按最大可用量采样\")\n",
    "            # 按比例重新计算采样数量\n",
    "            max_size1 = min(len(data1), target_size1)\n",
    "            max_size2 = min(len(data2), target_size2)\n",
    "            target_size1 = max_size1\n",
    "            target_size2 = max_size2\n",
    "        \n",
    "        print(f\"数据集1大小: {len(data1)}, 采样数量: {target_size1}\")\n",
    "        print(f\"数据集2大小: {len(data2)}, 采样数量: {target_size2}\")\n",
    "        \n",
    "        # 随机采样\n",
    "        selected1 = np.random.choice(len(data1), target_size1, replace=False)\n",
    "        selected2 = np.random.choice(len(data2), target_size2, replace=False)\n",
    "        \n",
    "        # 合并数据\n",
    "        mixed_data = []\n",
    "        for idx in selected1:\n",
    "            mixed_data.append(data1[idx])\n",
    "        for idx in selected2:\n",
    "            mixed_data.append(data2[idx])\n",
    "        \n",
    "        # 打乱数据顺序\n",
    "        np.random.shuffle(mixed_data)\n",
    "        \n",
    "        print(f\"混合后数据集大小: {len(mixed_data)}\")\n",
    "        return mixed_data\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"处理并保存混合数据集\"\"\"\n",
    "        # 1. 加载数据\n",
    "        self.load_data()\n",
    "        \n",
    "        # 2. 混合训练集\n",
    "        print(\"\\n混合训练集...\")\n",
    "        mixed_train = self.mix_data(\n",
    "            self.stage1_train,\n",
    "            self.stage2_train,\n",
    "            self.mix_ratio[\"stage1\"],\n",
    "            self.target_train_size\n",
    "        )\n",
    "        \n",
    "        # 3. 混合验证集\n",
    "        print(\"\\n混合验证集...\")\n",
    "        mixed_valid = self.mix_data(\n",
    "            self.stage1_valid,\n",
    "            self.stage2_valid,\n",
    "            self.mix_ratio[\"stage1\"],\n",
    "            self.target_valid_size\n",
    "        )\n",
    "        \n",
    "        # 4. 分析数据类型分布\n",
    "        print(\"\\n训练集类型分布:\")\n",
    "        train_type_stats = self.analyze_types(mixed_train)\n",
    "        \n",
    "        print(\"\\n验证集类型分布:\")\n",
    "        valid_type_stats = self.analyze_types(mixed_valid)\n",
    "        \n",
    "        # 5. 保存混合后的数据\n",
    "        train_path = os.path.join(self.output_dir, 'train.json')\n",
    "        valid_path = os.path.join(self.output_dir, 'valid.json')\n",
    "        \n",
    "        with open(train_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(mixed_train, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        with open(valid_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(mixed_valid, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        print(\"\\n数据保存完成：\")\n",
    "        print(f\"- 混合训练集: {train_path} ({len(mixed_train)} 条数据)\")\n",
    "        print(f\"- 混合验证集: {valid_path} ({len(mixed_valid)} 条数据)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mixer = DatasetMixer(\n",
    "        stage1_train_path='stage1/data_final/train.json',\n",
    "        stage1_valid_path='stage1/data_final/valid.json',\n",
    "        stage2_train_path='stage2/data_final/train.json',\n",
    "        stage2_valid_path='stage2/data_final/valid.json',\n",
    "        mix_ratio={\"stage1\": 0.7, \"stage2\": 0.3},\n",
    "        target_train_size=80000,  # 期望的训练集总数\n",
    "        target_valid_size=1000,    # 期望的验证集总数\n",
    "        output_dir='stage2/data_mixed'\n",
    "    )\n",
    "    \n",
    "    mixer.process()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据集...\n",
      "✓ Stage1 训练集: 80000 条数据\n",
      "✓ Stage1 验证集: 1000 条数据\n",
      "✓ Stage2 训练集: 41520 条数据\n",
      "✓ Stage2 验证集: 1000 条数据\n",
      "\n",
      "混合训练集...\n",
      "数据集1大小: 80000, 采样数量: 56000\n",
      "数据集2大小: 41520, 采样数量: 24000\n",
      "混合后数据集大小: 80000\n",
      "\n",
      "混合验证集...\n",
      "数据集1大小: 1000, 采样数量: 700\n",
      "数据集2大小: 1000, 采样数量: 300\n",
      "混合后数据集大小: 1000\n",
      "\n",
      "训练集类型分布:\n",
      "\n",
      "数据类型分布:\n",
      "- dialogue: 6030 条 (7.54%)\n",
      "- translation: 9178 条 (11.47%)\n",
      "- instruction: 56000 条 (70.00%)\n",
      "- story_generation: 8792 条 (10.99%)\n",
      "\n",
      "验证集类型分布:\n",
      "\n",
      "数据类型分布:\n",
      "- instruction: 700 条 (70.00%)\n",
      "- translation: 124 条 (12.40%)\n",
      "- story_generation: 111 条 (11.10%)\n",
      "- dialogue: 65 条 (6.50%)\n",
      "\n",
      "数据保存完成：\n",
      "- 混合训练集: stage2/data_mixed/train.json (80000 条数据)\n",
      "- 混合验证集: stage2/data_mixed/valid.json (1000 条数据)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
