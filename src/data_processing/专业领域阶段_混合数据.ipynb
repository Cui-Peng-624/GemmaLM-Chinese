{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainDatasetMixer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stage1_train_path: str,\n",
    "        stage1_valid_path: str,\n",
    "        stage2_train_path: str,\n",
    "        stage2_valid_path: str,\n",
    "        stage3_train_path: str,\n",
    "        stage3_valid_path: str,\n",
    "        mix_ratio: dict = {\"stage1\": 0.6, \"stage2\": 0.2, \"stage3\": 0.2},\n",
    "        target_train_size: int = 100000,  # 期望的训练集总数\n",
    "        target_valid_size: int = 1000,    # 期望的验证集总数\n",
    "        output_dir: str = \"stage3/data_mixed\"\n",
    "    ):\n",
    "        \"\"\"初始化专业领域数据集混合器\n",
    "        \n",
    "        Args:\n",
    "            stage1_train_path: 基础阶段训练数据路径\n",
    "            stage1_valid_path: 基础阶段验证数据路径\n",
    "            stage2_train_path: 特定任务阶段训练数据路径\n",
    "            stage2_valid_path: 特定任务阶段验证数据路径\n",
    "            stage3_train_path: 专业领域阶段训练数据路径\n",
    "            stage3_valid_path: 专业领域阶段验证数据路径\n",
    "            mix_ratio: 混合比例，字典格式\n",
    "            target_train_size: 期望的训练集总数\n",
    "            target_valid_size: 期望的验证集总数\n",
    "            output_dir: 输出目录\n",
    "        \"\"\"\n",
    "        self.stage1_train_path = stage1_train_path\n",
    "        self.stage1_valid_path = stage1_valid_path\n",
    "        self.stage2_train_path = stage2_train_path\n",
    "        self.stage2_valid_path = stage2_valid_path\n",
    "        self.stage3_train_path = stage3_train_path\n",
    "        self.stage3_valid_path = stage3_valid_path\n",
    "        self.mix_ratio = mix_ratio\n",
    "        self.target_train_size = target_train_size\n",
    "        self.target_valid_size = target_valid_size\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # 验证比例和是否为1\n",
    "        if abs(sum(mix_ratio.values()) - 1) > 1e-6:\n",
    "            raise ValueError(\"混合比例之和必须为1\")\n",
    "            \n",
    "        # 确保输出目录存在\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"加载所有数据集\"\"\"\n",
    "        print(\"正在加载数据集...\")\n",
    "        \n",
    "        # 加载三个阶段的数据\n",
    "        with open(self.stage1_train_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage1_train = json.load(f)\n",
    "        with open(self.stage1_valid_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage1_valid = json.load(f)\n",
    "            \n",
    "        with open(self.stage2_train_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage2_train = json.load(f)\n",
    "        with open(self.stage2_valid_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage2_valid = json.load(f)\n",
    "            \n",
    "        with open(self.stage3_train_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage3_train = json.load(f)\n",
    "        with open(self.stage3_valid_path, 'r', encoding='utf-8') as f:\n",
    "            self.stage3_valid = json.load(f)\n",
    "            \n",
    "        print(f\"✓ Stage1 训练集: {len(self.stage1_train)} 条数据\")\n",
    "        print(f\"✓ Stage1 验证集: {len(self.stage1_valid)} 条数据\")\n",
    "        print(f\"✓ Stage2 训练集: {len(self.stage2_train)} 条数据\")\n",
    "        print(f\"✓ Stage2 验证集: {len(self.stage2_valid)} 条数据\")\n",
    "        print(f\"✓ Stage3 训练集: {len(self.stage3_train)} 条数据\")\n",
    "        print(f\"✓ Stage3 验证集: {len(self.stage3_valid)} 条数据\")\n",
    "\n",
    "    def analyze_types(self, data):\n",
    "        \"\"\"分析数据集中各个类型的分布\"\"\"\n",
    "        type_counts = {}\n",
    "        domain_counts = {}\n",
    "        \n",
    "        for item in data:\n",
    "            # 统计数据类型\n",
    "            type_name = item.get('type', 'unknown')\n",
    "            type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
    "            \n",
    "            # 统计专业领域\n",
    "            domain = item.get('domain', 'general')\n",
    "            domain_counts[domain] = domain_counts.get(domain, 0) + 1\n",
    "            \n",
    "        print(\"\\n数据类型分布:\")\n",
    "        for type_name, count in type_counts.items():\n",
    "            percentage = (count / len(data)) * 100\n",
    "            print(f\"- {type_name}: {count} 条 ({percentage:.2f}%)\")\n",
    "            \n",
    "        print(\"\\n领域分布:\")\n",
    "        for domain, count in domain_counts.items():\n",
    "            percentage = (count / len(data)) * 100\n",
    "            print(f\"- {domain}: {count} 条 ({percentage:.2f}%)\")\n",
    "            \n",
    "        return type_counts, domain_counts\n",
    "    \n",
    "    def mix_data(self, data_list, ratios, target_size):\n",
    "        \"\"\"混合多个数据集\n",
    "        \n",
    "        Args:\n",
    "            data_list: 数据集列表\n",
    "            ratios: 对应的比例列表\n",
    "            target_size: 期望的混合后数据集大小\n",
    "        \"\"\"\n",
    "        mixed_data = []\n",
    "        \n",
    "        # 计算每个数据集需要的样本数\n",
    "        target_sizes = []\n",
    "        for i, ratio in enumerate(ratios):\n",
    "            if i == len(ratios) - 1:\n",
    "                # 最后一个数据集取剩余数量\n",
    "                size = target_size - sum(target_sizes)\n",
    "            else:\n",
    "                size = int(target_size * ratio)\n",
    "            target_sizes.append(size)\n",
    "        \n",
    "        # 检查并调整采样数量\n",
    "        for i, (data, target_size) in enumerate(zip(data_list, target_sizes)):\n",
    "            if target_size > len(data):\n",
    "                print(f\"警告：数据集{i+1}目标数量({target_size})超过可用数据量({len(data)})\")\n",
    "                target_sizes[i] = len(data)\n",
    "        \n",
    "        # 采样并合并数据\n",
    "        for data, size in zip(data_list, target_sizes):\n",
    "            print(f\"数据集大小: {len(data)}, 采样数量: {size}\")\n",
    "            selected = np.random.choice(len(data), size, replace=False)\n",
    "            mixed_data.extend([data[idx] for idx in selected])\n",
    "        \n",
    "        # 打乱数据顺序\n",
    "        np.random.shuffle(mixed_data)\n",
    "        \n",
    "        print(f\"混合后数据集大小: {len(mixed_data)}\")\n",
    "        return mixed_data\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"处理并保存混合数据集\"\"\"\n",
    "        # 1. 加载数据\n",
    "        self.load_data()\n",
    "        \n",
    "        # 2. 混合训练集\n",
    "        print(\"\\n混合训练集...\")\n",
    "        mixed_train = self.mix_data(\n",
    "            [self.stage1_train, self.stage2_train, self.stage3_train],\n",
    "            [self.mix_ratio[\"stage1\"], self.mix_ratio[\"stage2\"], self.mix_ratio[\"stage3\"]],\n",
    "            self.target_train_size\n",
    "        )\n",
    "        \n",
    "        # 3. 混合验证集\n",
    "        print(\"\\n混合验证集...\")\n",
    "        mixed_valid = self.mix_data(\n",
    "            [self.stage1_valid, self.stage2_valid, self.stage3_valid],\n",
    "            [self.mix_ratio[\"stage1\"], self.mix_ratio[\"stage2\"], self.mix_ratio[\"stage3\"]],\n",
    "            self.target_valid_size\n",
    "        )\n",
    "        \n",
    "        # 4. 分析数据分布\n",
    "        print(\"\\n训练集分布:\")\n",
    "        self.analyze_types(mixed_train)\n",
    "        \n",
    "        print(\"\\n验证集分布:\")\n",
    "        self.analyze_types(mixed_valid)\n",
    "        \n",
    "        # 5. 保存混合后的数据\n",
    "        train_path = os.path.join(self.output_dir, 'train.json')\n",
    "        valid_path = os.path.join(self.output_dir, 'valid.json')\n",
    "        \n",
    "        with open(train_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(mixed_train, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        with open(valid_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(mixed_valid, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        print(\"\\n数据保存完成：\")\n",
    "        print(f\"- 混合训练集: {train_path} ({len(mixed_train)} 条数据)\")\n",
    "        print(f\"- 混合验证集: {valid_path} ({len(mixed_valid)} 条数据)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mixer = DomainDatasetMixer(\n",
    "        stage1_train_path='stage1/data_final/train.json',\n",
    "        stage1_valid_path='stage1/data_final/valid.json',\n",
    "        stage2_train_path='stage2/data_final/train.json', # 都是用final的数据，mix是混合了stage1的数据\n",
    "        stage2_valid_path='stage2/data_final/valid.json',\n",
    "        stage3_train_path='stage3/data_final/train.json',\n",
    "        stage3_valid_path='stage3/data_final/valid.json',\n",
    "        mix_ratio={\"stage1\": 0.5, \"stage2\": 0.3, \"stage3\": 0.2},\n",
    "        target_train_size=80000,\n",
    "        target_valid_size=1000,\n",
    "        output_dir='stage3/data_mixed'\n",
    "    )\n",
    "    \n",
    "    mixer.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据集...\n",
      "✓ Stage1 训练集: 80000 条数据\n",
      "✓ Stage1 验证集: 1000 条数据\n",
      "✓ Stage2 训练集: 41520 条数据\n",
      "✓ Stage2 验证集: 1000 条数据\n",
      "✓ Stage3 训练集: 30000 条数据\n",
      "✓ Stage3 验证集: 1000 条数据\n",
      "\n",
      "混合训练集...\n",
      "数据集大小: 80000, 采样数量: 40000\n",
      "数据集大小: 41520, 采样数量: 24000\n",
      "数据集大小: 30000, 采样数量: 16000\n",
      "混合后数据集大小: 80000\n",
      "\n",
      "混合验证集...\n",
      "数据集大小: 1000, 采样数量: 500\n",
      "数据集大小: 1000, 采样数量: 300\n",
      "数据集大小: 1000, 采样数量: 200\n",
      "混合后数据集大小: 1000\n",
      "\n",
      "训练集分布:\n",
      "\n",
      "数据类型分布:\n",
      "- instruction: 40000 条 (50.00%)\n",
      "- ancient_poetry_creation: 5348 条 (6.69%)\n",
      "- translation: 9219 条 (11.52%)\n",
      "- classical_translation: 5342 条 (6.68%)\n",
      "- story_generation: 8861 条 (11.08%)\n",
      "- modern_poetry_creation: 5310 条 (6.64%)\n",
      "- dialogue: 5920 条 (7.40%)\n",
      "\n",
      "领域分布:\n",
      "- general: 80000 条 (100.00%)\n",
      "\n",
      "验证集分布:\n",
      "\n",
      "数据类型分布:\n",
      "- ancient_poetry_creation: 70 条 (7.00%)\n",
      "- story_generation: 110 条 (11.00%)\n",
      "- translation: 125 条 (12.50%)\n",
      "- instruction: 500 条 (50.00%)\n",
      "- classical_translation: 56 条 (5.60%)\n",
      "- dialogue: 65 条 (6.50%)\n",
      "- modern_poetry_creation: 74 条 (7.40%)\n",
      "\n",
      "领域分布:\n",
      "- general: 1000 条 (100.00%)\n",
      "\n",
      "数据保存完成：\n",
      "- 混合训练集: stage3/data_mixed/train.json (80000 条数据)\n",
      "- 混合验证集: stage3/data_mixed/valid.json (1000 条数据)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
