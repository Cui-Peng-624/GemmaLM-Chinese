Stage1（基础阶段）：
# AdaLoRA配置
```python
AdaLoRAConfig(
    r=64,
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    inference_mode=False,
    target_r=32,
    beta1=0.85,
    beta2=0.85,
    tinit=500,
    tfinal=2000,
    deltaT=10,
)
```

# 训练参数
```python
TrainingArguments(
    output_dir="../../../../../root/autodl-tmp/models/stage1/checkpoints/gemma-base-zh",
    learning_rate=5e-5,
    num_train_epochs=5,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    warmup_steps=500,
    logging_steps=100,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=500,
    fp16=True,
    optim="paged_adamw_32bit",
    lr_scheduler_type="cosine"
)
```

Stage2 (特定任务阶段)：
# AdaLoRA配置
```python
AdaLoraConfig(
    r=48,                    # 降低初始秩
    lora_alpha=24,          # 对应降低alpha
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    inference_mode=False,
    target_r=24,            # 降低目标秩
    beta1=0.85,
    beta2=0.85,
    tinit=400,              # 适当减少预热期
    tfinal=1500,            # 适当减少调整期
    deltaT=10,
)
```

# 训练参数
```python
TrainingArguments(
    output_dir="../../../../../root/autodl-tmp/models/stage2/checkpoints/gemma-base-zh",
    learning_rate=3e-5,     # 降低学习率
    num_train_epochs=4,     # 减少训练轮数
    per_device_train_batch_size=2,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    warmup_steps=400,       # 减少预热步数
    logging_steps=100,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=500,
    fp16=True,
    optim="paged_adamw_32bit",
    lr_scheduler_type="cosine"
)
```

Stage3 (专业领域阶段)：
# AdaLoRA配置
```python
AdaLoraConfig(
    r=32,                    # 进一步降低初始秩
    lora_alpha=16,          # 对应降低alpha
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    inference_mode=False,
    target_r=16,            # 进一步降低目标秩
    beta1=0.85,
    beta2=0.85,
    tinit=300,              # 进一步减少预热期
    tfinal=1000,            # 进一步减少调整期
    deltaT=10,
)
```

# 训练参数
```python
TrainingArguments(
    output_dir="../../../../../root/autodl-tmp/models/stage3/checkpoints/gemma-base-zh",
    learning_rate=2e-5,     # 进一步降低学习率
    num_train_epochs=3,     # 进一步减少训练轮数
    per_device_train_batch_size=2,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    warmup_steps=300,       # 进一步减少预热步数
    logging_steps=100,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=500,
    fp16=True,
    optim="paged_adamw_32bit",
    lr_scheduler_type="cosine"
)
```

参数变化梳理：
1. LoRA参数递减趋势：         
   初始秩(r):     64 -> 48 -> 32              
   目标秩:        32 -> 24 -> 16           
   lora_alpha:    32 -> 24 -> 16             
 
训练参数递减趋势：         
   学习率:        5e-5 -> 3e-5 -> 2e-5                
   训练轮数:      5 -> 4 -> 3             
   预热步数:      500 -> 400 -> 300               

AdaLoRA动态调整参数递减趋势：          
   tinit:         500 -> 400 -> 300           
   tfinal:        2000 -> 1500 -> 1000             

