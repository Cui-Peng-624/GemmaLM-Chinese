{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDL官方学术资源加速\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = \"/home/cuipeng/Gemma\"\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# 现在可以正常导入src下的模块\n",
    "from src.core.model.model_initializer import initialize_model_and_tokenizer\n",
    "from src.core.utils.model_utils import generate_response, apply_chat_template\n",
    "from src.core.solvers.l2m import L2MSolver\n",
    "from src.core.solvers.self_verification import SelfVerifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_verification\n",
    "\n",
    "import torch # type: ignore\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # type: ignore\n",
    "from transformers import BitsAndBytesConfig # type: ignore\n",
    "from peft import PeftModel  # type: ignore # 导入PeftModel用于加载微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSolver:\n",
    "    def __init__(self, l2m_solver, verifier):\n",
    "        \"\"\"\n",
    "        初始化增强型求解器\n",
    "        Args:\n",
    "            l2m_solver: 已初始化的 L2MSolver 实例\n",
    "            verifier: 已初始化的 SelfVerifier 实例\n",
    "        \"\"\"\n",
    "        if l2m_solver is None or verifier is None:\n",
    "            raise ValueError(\"必须提供已初始化的 L2MSolver 和 SelfVerifier 实例\")\n",
    "        \n",
    "        self.l2m = l2m_solver\n",
    "        self.verifier = verifier\n",
    "        \n",
    "        # 添加系统提示词\n",
    "        self.system_prompt = \"\"\"\n",
    "        你是一个专业的问题解决专家。你的任务是:\n",
    "        1. 分解复杂问题\n",
    "        2. 逐步解决子问题\n",
    "        3. 验证和改进答案\n",
    "        4. 整合最终解决方案\n",
    "\n",
    "        请确保答案:\n",
    "        - 准确完整\n",
    "        - 逻辑清晰\n",
    "        - 层次分明\n",
    "        - 易于理解\n",
    "        \"\"\"\n",
    "\n",
    "    def solve_complex_question(self, question):\n",
    "        \"\"\"使用增强的解决方案处理复杂问题\"\"\"\n",
    "        print(\"开始处理问题:\", question)\n",
    "        \n",
    "        # 1. 使用L2M获取初始解答\n",
    "        print(\"\\n1. 分解并解决问题...\")\n",
    "        l2m_result = self.l2m.solve(question) # l2m_result是一个字典\n",
    "        \n",
    "        # 2. 对每个子问题的解答进行验证和改进\n",
    "        print(\"\\n2. 验证和改进子问题解答...\")\n",
    "        verified_solutions = []\n",
    "        improved_context = \"\"\n",
    "        \n",
    "        for sub_solution in l2m_result[\"sub_solutions\"]: # 每个sub_solution都类似：{'question': , 'solution': }\n",
    "            print(f\"\\n处理子问题: {sub_solution['question']}\")\n",
    "            verified = self.verifier.verify_and_improve(\n",
    "                sub_solution[\"question\"],\n",
    "                sub_solution[\"solution\"]\n",
    "            )\n",
    "            \n",
    "            verified_solutions.append({\n",
    "                \"question\": sub_solution[\"question\"],\n",
    "                \"original_solution\": sub_solution[\"solution\"],\n",
    "                \"verified_solution\": verified[\"improved_answer\"],\n",
    "                \"verification_process\": {\n",
    "                    \"first_verification\": verified[\"first_verification\"],\n",
    "                    \"final_verification\": verified[\"final_verification\"]\n",
    "                }\n",
    "            })\n",
    "            improved_context += f\"\\n问题：{sub_solution['question']}\\n答案：{verified['improved_answer']}\\n\"\n",
    "        \n",
    "        # 3. 基于改进后的答案重新生成最终答案\n",
    "        print(\"\\n3. 生成最终答案...\")\n",
    "        dialogue = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": self.system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"基于以下解答过程，生成完整答案：\n",
    "\n",
    "解答过程：\n",
    "{improved_context}\n",
    "\n",
    "原始问题：{question}\n",
    "\n",
    "要求：\n",
    "1. 综合所有子问题的答案\n",
    "2. 保持逻辑连贯性\n",
    "3. 突出重点内容\n",
    "4. 语言简洁清晰\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        prompt = apply_chat_template(dialogue)\n",
    "        new_final_answer = generate_response(\n",
    "            self.l2m.model,\n",
    "            self.l2m.tokenizer,\n",
    "            prompt,\n",
    "            max_new_tokens=1536,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        # 4. 对最终答案进行验证和改进\n",
    "        print(\"\\n4. 验证和改进最终答案...\")\n",
    "        final_verified = self.verifier.verify_and_improve(\n",
    "            question,\n",
    "            new_final_answer\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_question\": question,\n",
    "            \"sub_solutions\": verified_solutions,\n",
    "            \"final_answer\": final_verified[\"improved_answer\"],\n",
    "            \"solution_process\": {\n",
    "                \"decomposition\": l2m_result[\"sub_solutions\"],\n",
    "                \"improved_context\": improved_context,\n",
    "                \"final_verification\": final_verified\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def analyze_verification_results(self, result):\n",
    "        \"\"\"分析验证结果，提供改进建议\"\"\"\n",
    "        analysis = {\n",
    "            \"sub_problems\": [],\n",
    "            \"final_answer\": {\n",
    "                \"improvement_level\": None,\n",
    "                \"key_improvements\": [],\n",
    "                \"remaining_issues\": []\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 分析子问题的改进\n",
    "        for sub_sol in result[\"sub_solutions\"]:\n",
    "            analysis[\"sub_problems\"].append({\n",
    "                \"question\": sub_sol[\"question\"],\n",
    "                \"verification_analysis\": self._analyze_verification(\n",
    "                    sub_sol[\"verification_process\"]\n",
    "                )\n",
    "            })\n",
    "        \n",
    "        # 分析最终答案的改进\n",
    "        final_verification = result[\"solution_process\"][\"final_verification\"]\n",
    "        analysis[\"final_answer\"].update(\n",
    "            self._analyze_verification(final_verification)\n",
    "        )\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "    def _analyze_verification(self, verification_data):\n",
    "        \"\"\"分析单个验证过程\"\"\"\n",
    "        return {\n",
    "            \"initial_issues\": self._extract_issues(verification_data[\"first_verification\"]),\n",
    "            \"resolved_issues\": self._extract_issues(verification_data[\"final_verification\"]),\n",
    "            \"improvement_summary\": self._compare_verifications(\n",
    "                verification_data[\"first_verification\"],\n",
    "                verification_data[\"final_verification\"]\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def _extract_issues(self, verification):\n",
    "        \"\"\"从验证结果中提取问题\"\"\"\n",
    "        # 这里可以添加更详细的解析逻辑\n",
    "        return verification\n",
    "\n",
    "    def _compare_verifications(self, first, final):\n",
    "        \"\"\"比较两次验证结果的差异\"\"\"\n",
    "        # 这里可以添加更详细的比较逻辑\n",
    "        return {\n",
    "            \"improved_aspects\": [],\n",
    "            \"remaining_issues\": []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfe10259080486c9633e41bcaed4308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/Gemma/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理问题: 请解释量子计算机的工作原理及其潜在应用。\n",
      "\n",
      "1. 分解并解决问题...\n",
      "\n",
      "2. 验证和改进子问题解答...\n",
      "\n",
      "处理子问题: \")\n",
      "\n",
      "处理子问题: for i, subproblem in enumerate(decompose_problem(question), start=1):\n",
      "\n",
      "处理子问题: print(f\"{i}. {subproblem}\")\n",
      "\n",
      "处理子问题: if __name__ == \"__main__\":\n",
      "\n",
      "处理子问题: main()\n"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化模型和tokenizer\n",
    "    model_path = \"google/gemma-2-9b\"\n",
    "    cache_dir = \"/root/autodl-tmp/gemma\"\n",
    "    # lora_path = \"/root/autodl-tmp/models/stage1/gemma-base-zh-final\"\n",
    "    lora_path = None\n",
    "    \n",
    "    model, tokenizer = initialize_model_and_tokenizer(\n",
    "        model_path=model_path,\n",
    "        cache_dir=cache_dir,\n",
    "        lora_path=lora_path,\n",
    "        use_quantization=True  # 确保使用量化\n",
    "    )\n",
    "    \n",
    "    # 初始化L2M求解器和验证器\n",
    "    l2m_solver = L2MSolver(model, tokenizer)\n",
    "    verifier = SelfVerifier(model, tokenizer)\n",
    "    \n",
    "    # 初始化增强求解器\n",
    "    solver = EnhancedSolver(\n",
    "        l2m_solver=l2m_solver,\n",
    "        verifier=verifier\n",
    "    )\n",
    "    \n",
    "    # 测试问题\n",
    "    question = \"请解释量子计算机的工作原理及其潜在应用。\"\n",
    "    \n",
    "    # 执行求解过程\n",
    "    result = solver.solve_complex_question(question)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(\"\\n最终答案:\", result[\"final_answer\"])\n",
    "    print(\"\\n解答过程分析:\", solver.analyze_verification_results(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
