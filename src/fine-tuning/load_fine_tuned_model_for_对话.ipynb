{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDL官方学术资源加速\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = \"/home/cuipeng/Gemma\"\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# 导入必要模块\n",
    "from src.core.model.model_initializer import initialize_model_and_tokenizer\n",
    "from src.core.utils.model_utils import generate_response, apply_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要模块\n",
    "from src.core.model.model_initializer import initialize_model_and_tokenizer\n",
    "from src.core.utils.model_utils import generate_response, apply_chat_template\n",
    "import ipywidgets as widgets # type: ignore\n",
    "from IPython.display import display, clear_output # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model_and_tokenizer():\n",
    "#     \"\"\"加载原始模型和tokenizer\"\"\"\n",
    "#     # 4bit量化配置\n",
    "#     quantization_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_compute_dtype=torch.float16,\n",
    "#         bnb_4bit_use_double_quant=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\"\n",
    "#     )\n",
    "    \n",
    "#     # 加载tokenizer\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\n",
    "#         \"google/gemma-2-9b\",\n",
    "#         cache_dir=\"/root/autodl-tmp/gemma\",\n",
    "#         trust_remote_code=True,\n",
    "#         local_files_only=True\n",
    "#     )\n",
    "    \n",
    "#     # 加载基础模型\n",
    "#     base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#         \"google/gemma-2-9b\",\n",
    "#         cache_dir=\"/root/autodl-tmp/gemma\",\n",
    "#         device_map=\"auto\",\n",
    "#         torch_dtype=torch.float16,\n",
    "#         quantization_config=quantization_config,\n",
    "#         local_files_only=True\n",
    "#     )\n",
    "    \n",
    "#     # 加载微调的LoRA权重\n",
    "#     model = PeftModel.from_pretrained(\n",
    "#         base_model,\n",
    "#         \"/root/autodl-tmp/models/stage1/checkpoints/gemma-base-zh/checkpoint-20000\"  # 微调模型的路径\n",
    "#     )\n",
    "    \n",
    "#     return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat_with_model():\n",
    "#     # 加载模型和tokenizer\n",
    "#     model, tokenizer = create_model_and_tokenizer()\n",
    "#     model.eval()  # 设置为评估模式\n",
    "    \n",
    "#     print(\"模型已加载完成，可以开始对话了！(输入 'quit' 结束对话)\")\n",
    "    \n",
    "#     while True:\n",
    "#         # 获取用户输入\n",
    "#         user_input = input(\"\\n用户: \")\n",
    "#         if user_input.lower() == 'quit':\n",
    "#             break\n",
    "            \n",
    "#         # 构建输入格式\n",
    "#         prompt = f\"<start_of_turn>user\\n{user_input}\\n<end_of_turn><eos>\\n<start_of_turn>model\\n\"\n",
    "        \n",
    "#         # 生成回答\n",
    "#         inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=512,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.95,\n",
    "#             do_sample=True,\n",
    "#             repetition_penalty=1.1\n",
    "#         )\n",
    "        \n",
    "#         # 解码模型输出\n",
    "#         response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "#         # 提取模型的回答部分（去除输入部分）\n",
    "#         response = response.split(\"<start_of_turn>model\\n\")[-1].split(\"<end_of_turn>\")[0].strip()\n",
    "        \n",
    "#         print(\"\\n助手:\", response)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     chat_with_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载模型和tokenizer\n",
    "# model, tokenizer = create_model_and_tokenizer()\n",
    "# model.eval()\n",
    "\n",
    "# # 修改输出区域的样式\n",
    "# conversation_output = widgets.Output(\n",
    "#     layout=widgets.Layout(\n",
    "#         width='100%',  # 设置宽度为100%\n",
    "#         max_width='1200px',  # 设置最大宽度\n",
    "#         min_height='400px',  # 设置最小高度\n",
    "#         border='1px solid #ddd',  # 添加边框\n",
    "#         overflow='auto',  # 添加滚动条\n",
    "#         word_wrap='break-word'  # 确保文本自动换行\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 修改输入框的样式\n",
    "# input_box = widgets.Text(\n",
    "#     value='',\n",
    "#     placeholder='请输入您的问题...',\n",
    "#     description='用户:',\n",
    "#     disabled=False,\n",
    "#     layout=widgets.Layout(\n",
    "#         width='80%',  # 调整宽度比例\n",
    "#         max_width='1000px'  # 设置最大宽度\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 修改按钮样式\n",
    "# send_button = widgets.Button(\n",
    "#     description='发送',\n",
    "#     disabled=False,\n",
    "#     button_style='primary',\n",
    "#     tooltip='发送消息',\n",
    "#     icon='paper-plane',\n",
    "#     layout=widgets.Layout(width='100px')  # 设置固定宽度\n",
    "# )\n",
    "\n",
    "# clear_button = widgets.Button(\n",
    "#     description='清空对话',\n",
    "#     button_style='warning',\n",
    "#     tooltip='清空对话历史',\n",
    "#     layout=widgets.Layout(width='100px')  # 设置固定宽度\n",
    "# )\n",
    "\n",
    "# # 修改按钮容器样式\n",
    "# button_container = widgets.HBox(\n",
    "#     [send_button, clear_button],\n",
    "#     layout=widgets.Layout(\n",
    "#         width='auto',\n",
    "#         margin='0 0 0 10px'  # 添加左边距\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 修改输入区域容器样式\n",
    "# input_container = widgets.HBox(\n",
    "#     [input_box, button_container],\n",
    "#     layout=widgets.Layout(\n",
    "#         width='100%',\n",
    "#         max_width='1200px',\n",
    "#         justify_content='space-between'  # 均匀分布空间\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # 修改主容器样式\n",
    "# main_container = widgets.VBox(\n",
    "#     [conversation_output, input_container],\n",
    "#     layout=widgets.Layout(\n",
    "#         width='100%',\n",
    "#         max_width='1200px',\n",
    "#         padding='10px',\n",
    "#         margin='0 auto'  # 居中显示\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# def on_send_button_clicked(b):\n",
    "#     user_input = input_box.value\n",
    "#     if not user_input.strip():\n",
    "#         return\n",
    "        \n",
    "#     input_box.value = ''\n",
    "    \n",
    "#     with conversation_output:\n",
    "#         print(f\"\\n用户: {user_input}\\n\")\n",
    "        \n",
    "#         prompt = f\"<start_of_turn>user\\n{user_input}\\n<end_of_turn><eos>\\n<start_of_turn>model\\n\"\n",
    "        \n",
    "#         inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=512,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.95,\n",
    "#             do_sample=True,\n",
    "#             repetition_penalty=1.1\n",
    "#         )\n",
    "        \n",
    "#         response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#         response = response.split(\"<start_of_turn>model\\n\")[-1].split(\"<end_of_turn>\")[0].strip()\n",
    "        \n",
    "#         # 使用HTML格式化输出\n",
    "#         display(HTML(f\"\"\"\n",
    "#         <div style=\"white-space: pre-wrap; word-wrap: break-word; width: 800px;\">\n",
    "#         <b>助手:</b> {response}\n",
    "#         </div>\n",
    "#         \"\"\"))\n",
    "#         print(\"-\" * 80)\n",
    "\n",
    "# def on_clear_button_clicked(b):\n",
    "#     conversation_output.clear_output()\n",
    "\n",
    "# # 绑定按钮事件\n",
    "# send_button.on_click(on_send_button_clicked)\n",
    "# clear_button.on_click(on_clear_button_clicked)\n",
    "\n",
    "# # 设置输入框回车发送\n",
    "# def on_enter(widget):\n",
    "#     on_send_button_clicked(None)\n",
    "# input_box.on_submit(on_enter)\n",
    "\n",
    "# # 显示主容器\n",
    "# display(main_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_interface():\n",
    "    \"\"\"创建聊天界面\"\"\"\n",
    "    # 初始化模型和tokenizer\n",
    "    model_path = \"google/gemma-2-9b\"\n",
    "    cache_dir = \"/root/autodl-tmp/gemma\"\n",
    "    # lora_path = \"/root/autodl-tmp/models/stage1/gemma-base-zh-final\"\n",
    "    lora_path = None\n",
    "    \n",
    "    print(\"正在加载模型...\")\n",
    "    model, tokenizer = initialize_model_and_tokenizer(\n",
    "        model_path=model_path,\n",
    "        cache_dir=cache_dir,\n",
    "        lora_path=lora_path,\n",
    "        use_quantization=True\n",
    "    )\n",
    "    model.eval()\n",
    "    print(\"模型加载完成!\")\n",
    "\n",
    "    # 修改输出区域的样式\n",
    "    conversation_output = widgets.Output(\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='1200px',\n",
    "            min_height='400px',\n",
    "            border='1px solid #ddd',\n",
    "            overflow='auto',\n",
    "            word_wrap='break-word'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 修改输入框的样式\n",
    "    input_box = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='请输入您的问题...',\n",
    "        description='用户:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(\n",
    "            width='80%',\n",
    "            max_width='1000px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 修改按钮样式\n",
    "    send_button = widgets.Button(\n",
    "        description='发送',\n",
    "        disabled=False,\n",
    "        button_style='primary',\n",
    "        tooltip='发送消息',\n",
    "        icon='paper-plane',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "\n",
    "    clear_button = widgets.Button(\n",
    "        description='清空对话',\n",
    "        button_style='warning',\n",
    "        tooltip='清空对话历史',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "\n",
    "    # 按钮容器\n",
    "    button_container = widgets.HBox(\n",
    "        [send_button, clear_button],\n",
    "        layout=widgets.Layout(\n",
    "            width='auto',\n",
    "            margin='0 0 0 10px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 输入区域容器\n",
    "    input_container = widgets.HBox(\n",
    "        [input_box, button_container],\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='1200px',\n",
    "            justify_content='space-between'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 主容器\n",
    "    main_container = widgets.VBox(\n",
    "        [conversation_output, input_container],\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='1200px',\n",
    "            padding='10px',\n",
    "            margin='0 auto'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def on_send_button_clicked(b):\n",
    "        user_input = input_box.value\n",
    "        if not user_input.strip():\n",
    "            return\n",
    "            \n",
    "        input_box.value = ''\n",
    "        \n",
    "        with conversation_output:\n",
    "            # 显示用户输入\n",
    "            print(f\"\\n用户: {user_input}\\n\")\n",
    "            \n",
    "            # 构建对话\n",
    "            dialogue = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"你是一个专业、友好的AI助手。请用简洁、准确的方式回答问题。\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_input\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # 生成回答\n",
    "            prompt = apply_chat_template(dialogue)\n",
    "            response = generate_response(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                prompt,\n",
    "                max_new_tokens=1024,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            print(f\"助手: {response}\\n\")\n",
    "            \n",
    "    def on_clear_button_clicked(b):\n",
    "        conversation_output.clear_output()\n",
    "\n",
    "    # 绑定按钮事件\n",
    "    send_button.on_click(on_send_button_clicked)\n",
    "    clear_button.on_click(on_clear_button_clicked)\n",
    "    \n",
    "    # 显示界面\n",
    "    display(main_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e717e0dcc9d74fb3ae583e7258367298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88073ce700fb418c8b71746310f1d71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border_bottom='1px solid #ddd', border_left='1px solid #ddd', border_right…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建聊天界面\n",
    "create_chat_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
