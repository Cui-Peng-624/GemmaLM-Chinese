{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDL官方学术资源加速\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = \"/home/cuipeng/Gemma\"\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# 导入必要模块\n",
    "from src.core.model.model_initializer import initialize_model_and_tokenizer\n",
    "from src.core.utils.model_utils import generate_response, apply_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要模块\n",
    "from src.core.model.model_initializer import initialize_model_and_tokenizer\n",
    "from src.core.utils.model_utils import generate_response, apply_chat_template\n",
    "import ipywidgets as widgets # type: ignore\n",
    "from IPython.display import display, clear_output # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_interface():\n",
    "    \"\"\"创建聊天界面\"\"\"\n",
    "    # 初始化模型和tokenizer\n",
    "    model_path = \"google/gemma-2-9b\"\n",
    "    cache_dir = \"/root/autodl-tmp/gemma\"\n",
    "    lora_path = \"/root/autodl-tmp/models/stage1/checkpoints/gemma-base-zh/checkpoint-43500\"\n",
    "    \n",
    "    print(\"正在加载模型...\")\n",
    "    model, tokenizer = initialize_model_and_tokenizer(\n",
    "        model_path=model_path,\n",
    "        cache_dir=cache_dir,\n",
    "        lora_path=lora_path,\n",
    "        use_quantization=True\n",
    "    )\n",
    "    model.eval()\n",
    "    print(\"模型加载完成!\")\n",
    "\n",
    "    # 添加系统提示词输入区域\n",
    "    system_prompt = widgets.Textarea(\n",
    "        value='你是一个专业、友好的AI助手。请用简洁、准确的方式回答问题。',\n",
    "        placeholder='请输入系统提示词...',\n",
    "        description='系统提示词:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            height='150px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 修改输出区域的样式，添加自动换行\n",
    "    conversation_output = widgets.Output(\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='800px',\n",
    "            min_height='400px',\n",
    "            border='1px solid #ddd',\n",
    "            overflow='auto',\n",
    "            padding='10px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 修改输入框，添加回车键支持\n",
    "    input_box = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='请输入您的问题...(按Enter发送)',\n",
    "        description='用户:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='700px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 按钮组件\n",
    "    send_button = widgets.Button(\n",
    "        description='发送',\n",
    "        disabled=False,\n",
    "        button_style='primary',\n",
    "        tooltip='发送消息',\n",
    "        icon='paper-plane',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "\n",
    "    clear_button = widgets.Button(\n",
    "        description='清空对话',\n",
    "        button_style='warning',\n",
    "        tooltip='清空对话历史',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "\n",
    "    test_prompt_button = widgets.Button(\n",
    "        description='测试系统提示词',\n",
    "        button_style='info',\n",
    "        tooltip='测试系统提示词是否生效',\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "\n",
    "    # 添加提示词显示控制\n",
    "    show_prompt_checkbox = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='显示完整Prompt',\n",
    "        indent=False\n",
    "    )\n",
    "\n",
    "    # 按钮容器\n",
    "    button_container = widgets.HBox(\n",
    "        [send_button, clear_button, test_prompt_button],\n",
    "        layout=widgets.Layout(\n",
    "            width='auto',\n",
    "            margin='0 0 0 10px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 输入区域容器\n",
    "    input_container = widgets.HBox(\n",
    "        [input_box, button_container],\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='1200px',\n",
    "            justify_content='space-between'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 创建左右布局容器\n",
    "    chat_container = widgets.VBox(\n",
    "        [conversation_output, input_container],\n",
    "        layout=widgets.Layout(\n",
    "            width='70%',\n",
    "            padding='10px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 系统设置容器\n",
    "    system_container = widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(value='<h4>系统设置</h4>'), \n",
    "            system_prompt,\n",
    "            show_prompt_checkbox\n",
    "        ],\n",
    "        layout=widgets.Layout(\n",
    "            width='28%',\n",
    "            padding='10px',\n",
    "            border='1px solid #ddd',\n",
    "            margin='0 0 0 10px'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 主容器\n",
    "    main_container = widgets.HBox(\n",
    "        [chat_container, system_container],\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            max_width='1200px',\n",
    "            margin='0 auto'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def send_message(text):\n",
    "        if not text.strip():\n",
    "            return\n",
    "            \n",
    "        input_box.value = ''\n",
    "        \n",
    "        with conversation_output:\n",
    "            # 显示用户输入\n",
    "            display(widgets.HTML(f\"<div style='margin: 10px 0'><b>用户:</b> {text}</div>\"))\n",
    "            \n",
    "            # 构建对话\n",
    "            dialogue = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt.value\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # 生成回答\n",
    "            prompt = apply_chat_template(dialogue)\n",
    "            \n",
    "            # 如果勾选了显示prompt，则显示完整prompt\n",
    "            if show_prompt_checkbox.value:\n",
    "                display(widgets.HTML(\n",
    "                    f\"<div style='margin: 10px 0; color: gray; font-size: 0.8em;'>\"\n",
    "                    f\"<b>完整Prompt:</b><pre>{prompt}</pre></div>\"\n",
    "                ))\n",
    "            \n",
    "            response = generate_response(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                prompt,\n",
    "                max_new_tokens=1024,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            # 显示助手回答\n",
    "            display(widgets.HTML(\n",
    "                f\"<div style='margin: 10px 0; white-space: pre-wrap;'>\"\n",
    "                f\"<b>助手:</b> {response}</div>\"\n",
    "            ))\n",
    "\n",
    "    def test_system_prompt(b):\n",
    "        with conversation_output:\n",
    "            display(widgets.HTML(\"<div style='color: blue'>正在测试系统提示词...</div>\"))\n",
    "            # 构建测试对话\n",
    "            dialogue = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt.value\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"你是谁？请介绍一下你自己。\"\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            prompt = apply_chat_template(dialogue)\n",
    "            \n",
    "            # 显示当前系统提示词\n",
    "            display(widgets.HTML(\n",
    "                f\"<div style='margin: 10px 0; color: gray; font-size: 0.8em;'>\"\n",
    "                f\"<b>当前系统提示词:</b><pre>{system_prompt.value}</pre></div>\"\n",
    "            ))\n",
    "            \n",
    "            # 如果勾选了显示prompt，则显示完整prompt\n",
    "            if show_prompt_checkbox.value:\n",
    "                display(widgets.HTML(\n",
    "                    f\"<div style='margin: 10px 0; color: gray; font-size: 0.8em;'>\"\n",
    "                    f\"<b>完整Prompt:</b><pre>{prompt}</pre></div>\"\n",
    "                ))\n",
    "            \n",
    "            response = generate_response(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                prompt,\n",
    "                max_new_tokens=1024,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            display(widgets.HTML(\n",
    "                f\"<div style='margin: 10px 0; white-space: pre-wrap;'>\"\n",
    "                f\"<b>助手的回答:</b> {response}</div>\"\n",
    "            ))\n",
    "\n",
    "    def on_send_button_clicked(b):\n",
    "        send_message(input_box.value)\n",
    "\n",
    "    def on_enter_pressed(widget):\n",
    "        send_message(widget.value)\n",
    "            \n",
    "    def on_clear_button_clicked(b):\n",
    "        conversation_output.clear_output()\n",
    "\n",
    "    # 绑定事件处理函数\n",
    "    send_button.on_click(on_send_button_clicked)\n",
    "    clear_button.on_click(on_clear_button_clicked)\n",
    "    test_prompt_button.on_click(test_system_prompt)\n",
    "    input_box.on_submit(on_enter_pressed)  # 添加回车键支持\n",
    "    \n",
    "    # 显示界面\n",
    "    display(main_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8634bc43ef9428a9c4cfcf3c763d5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/Gemma/lib/python3.12/site-packages/peft/tuners/adalora/config.py:78: UserWarning: Note that `r` is not used in AdaLora and will be ignored.If you intended to set the initial rank, use `init_r` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2304/268432009.py:240: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(on_enter_pressed)  # 添加回车键支持\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8041816ea8394042af5ef4ed23c2c522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Output(layout=Layout(border_bottom='1px solid #ddd', border_left='1px solid #ddd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建聊天界面\n",
    "create_chat_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
